{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05bf638c",
   "metadata": {},
   "source": [
    "# Normalization and batch correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3b2bb6",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567198f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path related settings (these should be the same as for the previous notebook)\n",
    "output_dir = '/mnt/workspace/jdetlef/ext_ana/processed'\n",
    "test = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose normalization method. If None, two normalization methods will be \n",
    "# performed and visualized with pca plot\n",
    "norm_method='total'  # can be 'tfidf' or 'total'\n",
    "# remove_pc1: if True, the first PC is removed from TFIDF-LSI normalization before calculating neighbors, \n",
    "# since first component correlates with number of features\n",
    "log_normalize=True\n",
    "\n",
    "# Highly Variable Features options \n",
    "min_cells = 5 # This one is mandatory\n",
    "max_cells = None\n",
    "\n",
    "# UMAP related settings \n",
    "metacol = 'Sample'\n",
    "\n",
    "# batch correction: If True, several batch correction methods will be performed,\n",
    "# you can choose the best one after\n",
    "batch_column = \"Sample\"\n",
    "perform_batch_correction = True\n",
    "batch_methods = [\"bbknn\", \"harmony\"] # \"mnn\", \"scanorama\"\n",
    "threads = 8\n",
    "\n",
    "# save figures\n",
    "save_figs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64aaa76",
   "metadata": {},
   "source": [
    "## Loading packages and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a4987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sctoolbox modules\n",
    "import sctoolbox.atac_tree as sub_tree\n",
    "import sctoolbox.creators as cr\n",
    "import sctoolbox.annotation as an\n",
    "from sctoolbox.qc_filter import *\n",
    "import sctoolbox.plotting as pl\n",
    "from sctoolbox.atac_utils import *\n",
    "from sctoolbox.analyser import *\n",
    "import sctoolbox.atac as atac\n",
    "# import episcanpy\n",
    "import scanpy as sc\n",
    "import episcanpy as epi\n",
    "#from episcanpy.preprocessing import _decomposition\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee657635",
   "metadata": {},
   "source": [
    "## Setup path handling object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aef88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an instance of the class\n",
    "tree = sub_tree.ATAC_tree()\n",
    "# set processing/output directory\n",
    "tree.processing_dir = output_dir\n",
    "# set sample/experiment.. \n",
    "tree.run = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1a8a9",
   "metadata": {},
   "source": [
    "## Load anndata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b56239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably updated in future\n",
    "qc_output = tree.qc_anndata  # path to qc_adata should be here\n",
    "adata = epi.read_h5ad(qc_output)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c62b5f",
   "metadata": {},
   "source": [
    "## Find highly variable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a2eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5823721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update number of cells per feature\n",
    "adata = analyser.calculate_qc_metrics(adata, var_type='features')\n",
    "# get highly variable features\n",
    "atac.get_variable_features(adata, max_cells, min_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e464de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of variable genes selected\n",
    "adata.var[\"highly_variable\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2be3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d2144",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_cutoffs_dec = input('Do you want to change the cutoffs again? answer with yes or no: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reset_cutoffs_dec.lower() == 'yes':\n",
    "    min_cells = input('Enter the minimal number of cells per feature?: ')\n",
    "    max_cells = input('Enter the maximum number of cells per feature?: ')\n",
    "    min_cells = int(min_cells)\n",
    "    max_cells = int(max_cells)\n",
    "    adata.var[\"highly_variable\"] = (adata.var['n_cells_by_counts'] <= max_cells) & (adata.var['n_cells_by_counts'] >= min_cells)\n",
    "    print('Number of highly variable features: ' + str(adata.var[\"highly_variable\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda16a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_HVF_distribution(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b520a",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider using parts of sctoolbox.analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a949c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if norm_method == 'tfidf':\n",
    "    print('Performing TFIDF and LSI...')\n",
    "    atac.tfidf(adata)\n",
    "    atac.lsi(adata)\n",
    "    print('Done')\n",
    "if norm_method == 'total':\n",
    "    print('Performing total and log1p normalization...')\n",
    "    sc.pp.normalize_total(adata)\n",
    "    adata.layers['normalised'] = adata.X.copy()\n",
    "    if log_normalize:\n",
    "        epi.pp.log1p(adata)\n",
    "    print('Done')\n",
    "if not norm_method:\n",
    "    adata_tfidf, adata_total = atac.atac_norm(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not norm_method:\n",
    "    user_norm = input('Choose a normalization method (total or tfidf): ')\n",
    "    if user_norm == 'total':\n",
    "        adata = adata_total\n",
    "    elif user_norm == 'tfidf':\n",
    "        adata = adata_tfidf\n",
    "else:\n",
    "    user_norm = None\n",
    "    \n",
    "display(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52137416",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96ceb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if norm_method == 'total':\n",
    "    print('Performing PCA')\n",
    "    sc.pp.pca(adata, svd_solver='arpack', n_comps=50, use_highly_variable=True)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130aff84",
   "metadata": {},
   "source": [
    "### Plot PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if norm_method == 'tfidf' or user_norm == 'tfidf':\n",
    "    # Change to module\n",
    "    if save_figs:\n",
    "        epi.pl.pca(adata, color=['nb_features'], show=False)\n",
    "        #plt.savefig(f'{OUTPUT_FIGS}/pca_nb_features.png')\n",
    "        plt.show()\n",
    "    else:\n",
    "        epi.pl.pca(adata, color=['nb_features'])\n",
    "        \n",
    "elif norm_method == 'total':\n",
    "    if save_figs:\n",
    "        epi.pl.pca_overview(adata, color=['nb_features'], show=False)\n",
    "        #plt.savefig(f'{OUTPUT_FIGS}/pca_nb_features.png')\n",
    "        plt.show()\n",
    "    else:\n",
    "        epi.pl.pca_overview(adata, color=['nb_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeca85b",
   "metadata": {},
   "source": [
    "## Calc Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "if norm_method:\n",
    "    if norm_method == 'tfidf' and remove_pc1:\n",
    "        print('Calculating neighbors')\n",
    "        sc.pp.neighbors(adata, n_neighbors=10, n_pcs=30, method='umap', metric='euclidean')\n",
    "    else:\n",
    "        print('Calculating neighbors')\n",
    "        sc.pp.neighbors(adata, n_neighbors=15, n_pcs=50, method='umap', metric='euclidean')\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f72f0",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6f9064",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.search_umap_parameters(adata, \n",
    "                       dist_range=(0.1, 0.4, 0.1), \n",
    "                       spread_range=(2.0, 3.0, 0.5), \n",
    "                       metacol=metacol, \n",
    "                       n_components=2, \n",
    "                       verbose=True, \n",
    "                       threads=4, \n",
    "                       save=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765a75e",
   "metadata": {},
   "source": [
    "## Batch Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c56436",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[batch_column] = adata.obs[batch_column].astype(\"category\") #ensure that batch column is a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15149b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_batch_correction:\n",
    "    batch_corrections = analyser.wrap_corrections(adata, \n",
    "                                              batch_key=batch_column,\n",
    "                                              methods=batch_methods)\n",
    "else:\n",
    "    batch_corrections = {\"uncorrected\": adata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8229b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run standard umap for all adatas\n",
    "analyser.wrap_umap(batch_corrections.values(), threads=threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should preliminary clustering be performed?\n",
    "do_clustering = True #True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform additional clustering if it was chosen\n",
    "color_by = []\n",
    "if do_clustering:\n",
    "    for adata in batch_corrections.values():\n",
    "        sc.tl.leiden(adata, 0.1)\n",
    "    color_by.append(\"leiden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b74605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate LISI scores for batch\n",
    "analyser.wrap_batch_evaluation(batch_corrections, batch_key=batch_column, threads=threads, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the overview of batch correction methods\n",
    "_ = pl.anndata_overview(batch_corrections, color_by=color_by, \n",
    "                       output=tree.norm_correction_plots + \"batch_correction_overview.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose an anndata object to proceed\n",
    "batch_name = input('Choose an anndata object to proceed. Type the name of the batch correction or uncorrected: ')\n",
    "try:\n",
    "    adata_corrected = batch_corrections[batch_name]\n",
    "except:\n",
    "    adata_corrected = batch_corrections['uncorrected']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fdbc93",
   "metadata": {},
   "source": [
    "## save anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623403df",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_output = tree.norm_correction_anndata\n",
    "adata_corrected.write(filename=adata_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132bfa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "repo_path = os.getcwd()\n",
    "notebook_name = '3_normalization_batch_correction.ipynb'\n",
    "notebook_path = os.path.join(repo_path, notebook_name)\n",
    "notebook_copy = os.path.join(tree.norm_correction_dir , notebook_name)\n",
    "shutil.copyfile(notebook_path, notebook_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a6ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
